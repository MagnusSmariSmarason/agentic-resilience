# AI Interaction Log

> Complete one entry for each significant AI interaction during the workshop. This log is a primary assessment artifact — it reveals your judgment, not just your output.

---

**Participant**: ___________________
**Date**: ___________________
**Problem Module**: ___________________

---

## Entry Template

### Interaction #___

**Tool used**: (e.g., Claude, ChatGPT, Copilot, Cursor)

**What I asked**: (Paste your prompt or describe the request)



**What it generated**: (Summarise the AI's response — don't paste the entire output)



**My decision**: (Circle one)

- [ ] **Accepted as-is** — Why was it good enough?
- [ ] **Modified** — What did I change and why?
- [ ] **Rejected** — What was wrong with it?
- [ ] **Used as starting point** — How did I build on it?

**Reasoning**: (Why did you make this decision? What did you evaluate?)



**What I learned**: (Did this interaction change your understanding?)



---

## End-of-Session Reflection

**How many interactions did you log?** ___

**What percentage did you accept without modification?** ___%

**If that percentage is above 80%, ask yourself**: Am I exercising judgment, or am I outsourcing it?

**If that percentage is below 20%, ask yourself**: Am I using the tool effectively, or am I resisting it?

**Most valuable AI interaction today**: (Which one taught you something or saved significant time?)



**Most misleading AI interaction today**: (Which one would have led you astray if you hadn't evaluated it?)



**One thing I'll do differently tomorrow**:

